
# Now let's begin with data_ingestion configuration

# creating the root folder as artifacts

artifacts_root : artifacts

# defining the data_ingestion coonfiguration

data_ingestion:
  # then again creating data_ingestion folder inside the artifacts
  root_dir: artifacts//data_ingestion
  # In future if we want to change the dataset we can just change the below link in config.yaml file instead of chaning the code in components
  source_URL: https://github.com/entbappy/Branching-tutorial/raw/master/winequality-data.zip
  local_data_file: artifacts/data_ingestion/data.zip
  unzip_dir: artifacts/data_ingestion


data_validation:
  root_dir: artifacts//data_validation
  unzip_data_dir : artifacts//data_ingestion//winequality-red.csv
  # when the data validation is performed on our data if it is in correct format it will return True else data validation False
  # Then only we will be starting the training pipelines only when the data is in correct format which saves the computational cost
  # Here we will be doing the schema.yaml validation
  STATUS_FILE : artifacts//data_validation//status.txt


data_transformation:
  root_dir : artifacts//data_transformation
  data_path : artifacts//data_ingestion//winequality-red.csv



model_trainer:
  root_dir : artifacts//model_trainer
  train_data_path : artifacts//data_transformation//train.csv
  test_data_path : artifacts//data_transformation//test.csv
  # we can also save the model as pkl format
  model_name : model.joblib